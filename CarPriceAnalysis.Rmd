---
title: "Car Price Analysis"
author: "Analysis by: Alyssa Aey, Olivia Bickford, and Lauren Pagel"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
date: "2024-09-09"
---


In this analysis, we will be exploring one set of data that is focused on different car features that may impact the sale price of a car. The set of data is taken from different car observations.

The data set we will be examining consists of 12 variables, 11 of which are classified as predictor variables. 11 of these variables are observatory, while 1, symboling, represents an assigned insurance risk rating for the vehicle.

This data set will be read into R from a CSV file and will be named as car_price during our analysis.

# Descriptive Summary

## Data Structure
```{r, echo = FALSE}
## load the dataset
car_price <- read.csv('CarPrice.csv')
```

Once the data set is loaded into the software, we first want to examine the structure of the data set. This will give us an idea of what variables are present, as well as what types they are as we begin to perform our analysis.

```{r, echo=FALSE}
str(car_price)
```
From this, we can see that all of our predictor variables are either numeric or an integer, besides the drivewheel, which is classified as a character. From this one line of code we are also able to see that we have a total of 205 observations across 11 predictor variables and one response variable.
```{r, echo=FALSE}
head(car_price)
```
Shows the first few observations of the data set.
```{r, echo=FALSE}
tail(car_price)
```
Shows the last few observations of the car_price data set.

## Summary Statistics
```{r, echo=FALSE}
## Show summary of all variables in dataset
summary(car_price)
```


This showcases summary statistics for each variable in the model. These summary statistics will be referenced later on when looking for outliers in the data set and provide useful information about the distribution of values.


## Data Quality Assessment
Before doing any initial analysis on the data, it is important to understand the overall quality of the current data that we are given. Without quality data, we are unable to draw any meaningful conclusions, so it is important that all data quality problems are taken care of immediately.

First, we will check for any missing values in our dataset.
```{r, echo=FALSE}
## Check for Missing Values
missing_values <- car_price |> 
  dplyr::summarise_all(~ sum(is.na(.)))

print(missing_values)
```
There are no missing values in the car prices data set.

Next, we will look to see if any of the rows have duplicated values.
```{r,echo=FALSE}
## Check for duplicated rows
duplicate_rows <- car_price |> 
  dplyr::filter(duplicated(car_price))

print(duplicate_rows) 
```
We found that there were two rows duplicated in our data set. However, by looking closer at the values, only 6 out of 11 possible predictor variables were exact duplicates of one another. Because this does not appear to be an exact duplicate of records, we will continue with our analysis.

The next step in ensuring data quality is to examine the distribution of predictor variables to see if there are any outliers.
```{r, echo=FALSE}
numeric_data <- car_price[sapply(car_price, is.numeric)]
boxplot(numeric_data, main = "Boxplot of Car Prices Data Set", ylab = "Values", las = 2)
```

From creating a boxplot of all predictor variables in the data set, we can see that variables wheelbase, carlength, cylinder number, stroke, horsepower, peakrpm, and citympg have at least one outlier. In addition, our response varaible, price, has at least one outlier present. Let's investigate further.
```{r, echo=FALSE}
boxplot(car_price$wheelbase, main = "Distribution of Wheelbase",
        ylab = "Values")
```
It looks like there are two outliers of the wheelbase variable.
```{r, echo=FALSE}
summary(car_price$wheelbase)
```

According to [carparts.com](https://www.carparts.com/blog/what-is-the-wheelbase-and-how-does-it-affect-car-performance/#:~:text=For%20example%2C%20a%20city%20car,typically%20has%20around%20117%20inches) the wheelbase size is typically dependent on the size of the car. For instance, a city car typically has a 95 inch wheelbase while a large SUV has around 117 inches. With a max value of 120.90 inches, our outliers for this variable do not appear to be very far removed from the dataset at all, and are likely a better indication of a larger vehicle. Thus, we will leave these observations in our data set. 

The next variable we will investigate is the length of the car.
```{r, echo=FALSE}
boxplot(car_price$carlength, main = "Distribution of Car Length",
        ylab = "Values")
```

Looking at the distribution of values of the car length variable, it appears we have one outlier. Let's take a look at the summary statistics.
```{r, echo=FALSE}
summary(car_price$carlength)
```

According to [carfromjapan.com](https://carfromjapan.com/article/car-maintenance/what-is-the-average-car-length-and-how-to-find-it/), the length of a small car can be anywhere between 118 and 169.3 inches. With this information, we can see that our small outlier clearly falls within the range. We are free to proceed with this data point in our data set.

The next variable we will look at is the cylinder number of the car.
```{r, echo=FALSE}
boxplot(car_price$cylinder.number, main = "Distribution of cylinder number",
        ylab = "Values")
```

According to [Kia](https://www.kia.com/dm/discover-kia/ask/what-is-a-cylinder-in-a-car.html#:~:text=The%20cylinder%20consists%20of%20a,6%2C%20or%208%20cylinder%20engine.), most cars have either a 4, 6, or 8, cylinder engine, however it is possible to have more or less than that. With this information, we can determine that we are safe to proceed with these observations in our data.

The next variable with outliers present is the stroke of the engine.
```{r, echo=FALSE}
boxplot(car_price$stroke, main = "Distribution of Stroke",
        ylab = "Values")
```

The values for the distribution of the stroke do not seem like outliers. With some additional research, most cars have a 3-stroke engine. However, a lot of modern cars have a 4-stroke engine and many older cars have a 2-stroke engine.This information was found from [Prime Source](https://primesourceco.com/latest-news/the-difference-between-a-2-stroke-and-4-stroke-engine/#:~:text=While%204%2Dstroke%20engines%20perform,stroke%20is%20more%20fuel%2Defficient). Thus, we can conclude that these values are likely not outliers and are more indicative of the age of the car.

The next variable that we will examine for outliers is the horsepower of the engine.
```{r, echo=FALSE}
boxplot(car_price$horsepower, main = "Distribution of Horsepower",
        ylab = "Values")
```

By closely looking the boxplot for the horsepower of an engine, our outliers for this variable appeared to be skewed towards high values in the dataset. According to [AutoList](https://www.autolist.com/guides/average-car-horsepower), the horsepower for car engines most often depends on the size of the car. For small cars, a good horsepower is typically between 100-150. For midsize cars, a good horsepower is around 200. For large cars, a good horsepower is around 300. In addition, a good horsepower for a sports car falls above 300. Thus, these higher values are likely not outliers in the dataset and are likely better indicators of the type of car.

The next variable we will examine for outliers is PeakRPM.
```{r, echo=FALSE}
boxplot(car_price$peakrpm, main = "Distribution of Peak RPM",
        ylab = "Values")
```

From this boxplot, it appears that we have one outlier of peak RPM in our dataset. According to [Auto Hero](https://www.autohero.com.au/blog/what-does-rpm-mean-in-a-car/#:~:text=What%20is%20maximum%20RPM%20for,lower%20%E2%80%93%20usually%20around%204%2C000RPM.), the peak RPM of a car depends on the type of engine used. For example, petrol engines have a max RPM between 5,000 and 7,000RPM. Diesel engines have a lower max RPM around 4,000RPM, however most cars under normal driving conditions operate between 1,500-3,000RPM. The summary statistics shown earlier indicates a maximum value in our data set of 6600, which we can conclude is an acceptable value to leave in our data set.

The final predictor variable we will check for outliers is the city miles per gallon.
```{r, echo=FALSE}
boxplot(car_price$citympg, main = "Distribution of City MPG",
        ylab = "Values")
summary(car_price$citympg)
```

The two outliers in our boxplot do not appear to be very far away from the range in our boxplot. In addition, according to research from [Car and Driver](https://www.caranddriver.com/research/a31518112/what-is-good-gas-milage/), these outliers are possible potential values for gas mileage and thus should be left in the data.

As mentioned previously, our response variable, price, also had a few outliers visible. Let's take a closer look at this:
```{r, echo=FALSE}
boxplot(car_price$price, main = "Distribution of Price",
        ylab = "Values")
```
From this boxplot, it appears that our data is slightly skewed to the right with higher car prices in the data set. According to the summary statistics above, the maximum price of a car in our data is $45,400. [Yahoo Finance](https://finance.yahoo.com/news/car-prices-drop-2024-auto-120055933.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAE6-YTs4XuYqnckDJIgBBxcNMXUL9__xXwcnBgqjTZB2fmEts9HnM1pKg00IkW_hSkr2t5shJpiujBZ17VyIIDQwEByhD9gWDIEiIQRh9ZGcUuiV85qGZ-rh_Z0Pc54-UAzRCvrR_KYzm7MPOleOkRxB_wLmf5397P3len-sY1ti) states in their article that the average new car in October of 2023 was selling for $47,936. From this new information, we can take note that as new cars are added to our data set, the car prices will start to shift towards our current outlier values, meaning that it is okay to proceed with these values in our data set.

Now that we have closely checked for data quality in our data set, we will proceed by examining correlations between variables and begin to understand the relationships they may have on car price.

## Visualizations
This section will primarily focus on building visualizations to better understand the data and correlations between variables.

To start, we will compute the correlations for each numeric predictor variable with the response
```{r, echo=FALSE}
# Identify numeric columns
numeric_vars <- sapply(car_price, is.numeric)

# Extract only numeric columns
car_price_numeric <- car_price[, numeric_vars]

# Extract the dependent variable 'price'
dependent_var <- car_price_numeric$price

# Compute correlations with the dependent variable
correlations <- sapply(car_price_numeric, function(x) {
  if (identical(x, dependent_var)) {
    NA  # Skip the correlation of 'price' with itself
  } else {
    cor(x, dependent_var, use = "complete.obs")
  }
})

# Print correlations
print(correlations)
```

From this block of code, we are able to view the correlations each of our numeric predictor variables with the response variable, car price. The correlation coefficient, r, indicates the strength and direction of each correlation, with the strongest correlation values approaching either -1 or +1 based on the direction.

From this information, we notice that the predictor variable with the strongest regression relationship with car price is the curbweight of the car. Let's investigate this further.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = curbweight, y = price) +
  geom_point() +
  scale_color_hue()
```

As indicated by the correlation coefficient of 0.8353, we see from a scatterplot of the data points that as the weight of the car increases, the overall price of the car also tends to increase. These variables appear to have a relatively strong relationship with one another. There may even be a statistically significant linear relationship between these variables, however further testing and modeling would be needed.

From the correlation coefficients shown above, horsepower was also showen to be a relatively strong predictor of car price. Let's examine its scatterplot.

```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = horsepower, y = price) +
  geom_point() +
  scale_color_hue()
```
Similar to the curbweight of the car, we find that typically as the horsepower of the car increases, so does its price. These variables also have a relatively strong relationship with one another (r = 0.8081), indicating that there may even be a statistically significant relationship between these predictors, however, more analysis would be needed to prove this.

Let's look at a variable with a relatively low correlation coefficient, stroke.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = stroke, y = price) +
  geom_point() +
  scale_color_hue()

```

As indicated by its correlation coefficient (r = 0.0794), there is a weak relationship present between stroke and the price of a car. Further analysis would be needed, but this may be an indication of a statistically insignificant relationship between the variables, meaning that an engine's stroke may not be a good indicator of a car's price.

With some of this information, let's generate a correlation matrix.
```{r, echo=FALSE}
# Install the corrplot package if it's not already installed
if (require(corrplot) == FALSE) install.packages("corrplot")

# Load the corrplot package
corrplot::corrplot(cor(car_price_numeric))

car.cor = cor(car_price_numeric)
corrplot(car.cor)
```

Above is a correlation matrix of all of our numeric predictor variables. This plot shows the relationship that all of our predictor variables have with the response as well as the relationships the predictor variables have with one another. This is particularly useful to best understand the relationships present in the dataset for further analysis in the future.

While we were able to examine all of the correlation coefficients for our numeric predictors, we were unable to see if our one categorical predictor, drivewheel has any impact on the car price.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = drivewheel, y = price) +
  geom_point() +
  scale_color_hue()
```

This plot categorizes the observations by the type of drive wheel it has, either "rear-wheel drive" or "other." From the plot generated, we see that vehicles classified as having a rear-wheel drive typically have a higher car price than those categorized as other. This indicates that there could potentially be a relationship between the drivewheel of a vehicle and car price, however we would still need further analysis.

# Observation, Research, Hypothesis
In this section of our analysis, we will focus on developing hypotheses that may be relevant to better understanding the relationships between our predictor variables and car price. 

## Curb Weight is a Statistically Significant Predictor of Car Price
In the above section, we examined the correlations between each predictor variable and car price. With a correlation coefficient of 0.8353, we see that there is a relatively strong positive correlation between the curb weight of a car and the car price. As the curb weight of the car increases, the car price tends to increase as well.

### Doing Research
The vehicle's curb weight is defined as the weight of the vehicle. This includes a full tank of fuel and all standard equipment such as motor oil, transmission oil, and brake fluid. This differentiates from a vehicle's gross weight which denotes the total weight from a vehicle when it is fully loaded with passengers, cargo, and additional equipment. 

It is also said that curb weight "acts as a baseline measurement that directly impacts several aspects of vehicle performance." These aspects include fuel efficiency and acceleration. It is said that vehicles with lower curb weights reduce the amount of power required to move the vehicle, which result in less fuel consumed. In addition, lighter vehicles have an advantage when it comes to acceleration. However, when we look at vehicle stability in adverse weather conditions, heavier vehicles hold their ground better. 

For the most part, larger cars have larger gas tanks than smaller cars. Small cars usually hold up to 12 gallons gas, some larger cars can carry 15 gallons of gas, and many larger trucks can hold anywhere from 21-38 gallons of gas. 

Through research, there is no definitive answer as to how the size of a car's gas tank and the price of the car are related. However, we can say that as the size of gas tanks increase, so does the overall curbweight of the car. Perhaps the extra sales price that is shown from the positive correlation is a better result of the additional materials cost to build a larger car.

### Testing this Hypothesis
In order to test this hypothesis, we want to run a regression model to show its validity. Our regression model will use curbweight as the predictor variable and car price as the repsonse variable. From there we will run a one-sample t-test to examine whether there is a significant regression relationship between curbweight and car price.

## Horsepower and Amount of Cylinders is a Statistically Significant Predictor of Car Price

Above horsepower and price have a positive correlation of 0.808 so we see there is a strong, positive linear correlation between these two variables. So, as the horsepower of a car increases the price tends to increase. Between amount of cylinders and price, there is also a strong positive correlation of 0.718. This means that as the price increases as the amount of cylinders increases. On the correlation plot, horsepower and the amount of cylinders has a strong positive linear association. 


### Doing Research

Horsepower is the power of the engines and the rate at which work is done. Horsepower sustains the momentum and higher rate of work once the car is moving. The higher the horse power, the faster the engine will accelerate at speed. Horsepower shows the performance of a car, an engine with more horsepower will accelerate more quickly and can lead to more towing reliability. With this however, higher horsepower can often lead to lower gas mileage and efficiency. 

The cylinder is the power unit of the engine and there are usually 4, 6 or 8 in a car. These take fuel and burn it so it is turned into energy that in turn powers the vehicle. It has the base of a piston that moves the cylinder up and down to form the reaction and combustion. The more cylinders means more pistons leading to more fuel being turned into power. 

With research there seems to be no definitive answers about horsepower and cylinder are related to a higher car price. However, it seems that the more horsepower the car is stronger and the more cylinders there are the more gas and power the car is producing. The additional price increase could be due to more advanced and powerful technology required for having a higher horsepower. The higher the performance could require more expensive components in order for the car to preform up to standard. The more cylinders usually means larger engines in order to fit everything properly so there could be an increased in the complexity of materials needed to fit multiple cylinders. 

Thinking about fuel efficiency, cars with larger engines have a lower fuel efficiency and higher emissions due to the amount of gas required to power the car. With many business and governments putting rules in place about environmental regulations, the manufacturer might have to add an increase in price to comply with the rules due to cars with more horsepower and more cylinders that could contribute more to carbon emissions. 


### Testing this Hypothesis

In order to test this hypothesis a multiple regression could be used to model the relationship since there are strong positive correlation values between the variables and adding in interaction terms to see if horsepower depends on the number of cylinders or vise versa. 

Our model would use horsepower and number of cylinders as predictor variables and car price as the response. We would use a one sample t-test to compare the average prices and see if there is a significant relationship between the two variables and the predictor. From there we would assess the model fit with R-squared values, residual analysis and test sets. 

## Curb Weight and Horsepower are statistically significant predictors of a City MPG
We generated this hypothesis from the results of our correlation matrix. From this we noticed that there were relatively large negative correlations between these variables. 
```{r}
cor(car_price$curbweight, car_price$citympg, use = "complete.obs")
```
This line of code shows that curb weight has a relatively strong negative relationship with city mpg. This means that as curb weight tends to increase, the miles per gallon the car gets tends to decrease.
```{r}
cor(car_price$horsepower, car_price$citympg, use = "complete.obs")
```
This line of code confirms what we have seen from our correlation matrix and even suggests that horsepower is a stronger predictor of city mpg than the curb weight of the car is. We will continue to work with our hypothesis that both are strong predictors of city mpg, but horsepower may even be one on its own.

### Doing Research
One critical factor that we saw from doing research on both horsepower and the curb weight of the car is something called a [Power to Weight Ratio](https://www.jtech.org/power-to-weight-ratio-and-how-it-affects-performance/). Essentially, the power to weight ratio is calculated by dividing the horsepower of the car by the weight of the car. According to the article, the ideal performance of a car is lighter in curb weight but high in the amount of horsepower.

Of course, it depends how you would want to describe vehicle performance, which could mean different things depending on the context of the situation. In this scenario, we will be looking at vehicle performance in the context of miles per gallon the vehicle is able to get.

Regression analyses has been done to show the regression relationship between both horsepower, curb weight, and city mpg. In a study done by [Fort Hays State University](https://scholars.fhsu.edu/cgi/viewcontent.cgi?article=1427&context=sacad), both the weight and horsepower of a car are shown to be statistically significant predictors of the fuel efficiency (mpg) of a vehicle. 

Other [studies](https://finelineimports.net/2019/10/does-more-horsepower-mean-fewer-mpg/) have shown the exact opposite, that horsepower is not an issue that can affect fuel economy. This approach claims that there are a variety of other factors that impact a vehicle's fuel efficiency such as "easing off of the accelerator, cutting down on some of the weight inside your vehicle, keeping tires inflated to the proper pressure, reducing drag as much as possible, and taking routes you won't have to stop as frequently." 

Because of the mixed results we found through our outside research, particularly in regards to horsepower, it makes it all the more important to test our hypothesis on our own data set before jumping to any conclusions.

### Testing this Hypothesis

In order to test this hypothesis, we will build a multiple regression model using both horsepower and curbweight as predictor variables and city miles per gallon as the response variable. 

After building the regression model, we will examine the F test statistic in order to determine the overall model significance. In addition, measures such as the adjusted R2 and RMSE will provide insight into how well our model performs. In addition, one-sample t-tests can be performed on each predictor variable in order to test their individual significance to the model.

# Running our Analyses
Now that we have identified, three potential hypotheses to test we need to test them to see if they hold true in our model

## Curb Weight is a Statistically Significant Predictor of Car Price
```{r}
reg1 = lm(price~curbweight, data = car_price )
```
```{r, echo = FALSE}
# Load the necessary libraries
ggplot2::ggplot(car_price, ggplot2::aes(x = curbweight, y = price)) +
  ggplot2::geom_point() +  # Scatter plot
  ggplot2::geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Best fit line
  ggplot2::labs(title = "Scatterplot of Price vs. Curbweight",
                x = "Curbweight",
                y = "Price")
```


### Establishing Our Null and Alternative Hypothesis
As we discussed above, we planning on building a regression model using curb weight as a predictor of car price. We will then run a t-test to test the overall significance of curb weight as a predictor variable

In order to test the significance of curb weight as a predictor of car price we will establish the null and alternative hypothesis as such:
- Null Hypothesis: β1 = 0. This means that curb weight is not a significant predictor of car price
- Alternative Hypothesis: β1 ≠ 0. This means that curb weight is a significant predictor of car price.

### Checking our Assumptions
Now that we have established both our null and alternative hypothesis, we will proceed by checking our assumptions of linear regression.

#### The Mean of ε is ZERO
The first assumption that we will check is that the mean of the error term, ε, is zero. This assumption means that the model is not biased.
```{r}
residuals_1 = reg1$residuals
mean(residuals_1)
```

#### Constant Variance
```{r, echo = FALSE}
library(ggplot2)
ggplot(reg1, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")
```

This assumption may not hold exactly because we can see that the residuals do not have constant variance for all values.

#### Error Term is Normal
```{r}
plot(reg1, 2)
```

From the QQ plot above, with its distribution, we can conclude that the assumption that the error term of ε is mostly normal with some of the data points being slightly under or below the line.

#### ϵi are Independent
In order to test this assumption, we would need to have a time variable included in the model. However, there is no time variable in the regression model to test this hypothesis.

### Performing our Test
Now that we have checked our assumptions, we will move forward with reporting our test statistic and p-value for our tests. It will be important to note that we will need to proceed with caution because assumption 2, constant variance, is not met within our current data set.

```{r}
summary(reg1)
```
As noted earlier, we will be reporting on the one-sample t test for our hypothesis test. With a t-value of 21.65, and a p-value of close to 0, which is less than our alpha level, 0.01, we reject the null hypothesis. We have sufficient evidence to show that curb weight is a significant predictor of car price based on our sample. However, we should proceed with caution because not all of our assumptions were met.


## Horsepower and Amount of Cylinders is a Statistically Significant Predictor of Car Price
```{r}
reg2 <- lm(price ~ horsepower + cylinder.number + horsepower:cylinder.number, data = car_price)
```



### Establishing our Null and Alternative Hypothesis
As we discussed above, we plan on running an F-test to test the overall significance of both the horsepower of the car, the amount of cylinders and the interaction between them as a predictor of car price.


In order to test the significance of the overall regression model, we establish the null and alternative hypothesis as such:
    - Null Hypothesis: β1 = β2 = 0. This means that none of the variables have an overall significance in the regression model
    - Alternative Hypothesis: At least one βn ≠ 0. This means that at least one predictor variable is significant in our multiple regression model.

In addition to testing the significance of the overall regression model, we will test the significance of each individual predictor variable in our model, number of cylinders and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the predictior variable we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the individual predictor variable is significant in the overall model.
  
In addition to testing the significance of the overall regression model, we will test the significance of the interaction terms between the number of cylinders and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the interaction term we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the interaction term is significant in the overall model.

### Checking our Assumptions

#### The Mean of ε is ZERO
The first assumption that we will check is that the mean of the error term, ε, is zero. This assumption means that the model is not biased.
```{r}
residuals_2 = reg2$residuals
mean(residuals_2)
```
As you can see from the above code, the mean of the residuals is approximately zero, therefore we can check off this assumption.

#### Constant Variance
The second assumption that we will check is that we have constant variance.
```{r, echo = FALSE}
plot(reg2, 1)
```

This assumption may not hold exactly because we can see that the residuals do not have constant variance for all values and the residual line is slightly skewed up.

#### Error Term is Normal
The next assumption that we check is that error term is normal.
```{r, echo = FALSE}
plot(reg2, 2)
```

From the QQ plot above, with its distribution, we can conclude that the assumption that the error term of ε is mostly normal with some of the data points being slightly under or below the line.

#### ϵi are Independent
In order to test this assumption, we would need to have a time variable included in the model. However, there is no time variable in the regression model to test this hypothesis.

### Performing Tests
Now that we have checked our assumptions, we will move forward with reporting our test statistics and p-values for our tests. It will be important to note that we will need to proceed with caution because assumption 2, constant variance, is not met within our current data set.

#### F Test for Overall Model Significance
```{r}
summary(reg2)
```
As shown by the summary, the F-statistic of this test is 171.1. There is a p-value reported of <0.001, meaning that we can reject our null hypothesis. From our test, we can conclude that we can reject our null hypothesis and say that at least one of predictor of horsepower, number of cylinders and the interaction term are significant predictors of car price. However, it is important to proceed with caution with this because not all of our assumptions above were met.

An adjusted R2 value of 0.7144 implies that 71.44% of the variation in car price can be explained by the regression relationship between horsepower and number of cylinders. In addition, a RMSE value of 4269 shows that there is a higher average size of the residuals. This means we should proceed with caution.


#### T Test for Individual Variable Significance
While it is important to show how these variables work together, it is also important to check if they are significant predictors on their own. For this, we will reference the above summary and perform one-sample t-tests.

The predictor variable of number of cylinders has a test statistic value of 5.602 With a p-value of less than 0.001, we can conclude that we can reject our null hypothesis and say that number of cylinders is a significant predictor of car price in our multiple regression model.

The predictor variable of horsepower has a test statistic value of 8.221, With a p-value of less than 0.001, we can conclude that we can reject our null hypothesis and say that horsepower is a significant predictor of car price in our multiple regression model.

#### Interaction Terms
The interaction between horsepower and cylinder number shows how the effect of horsepower on the car price changes depending on the level of the other predictor, cylinder number. Since the p-value for the interaction terms is <0.001, the effect of one predictor on car price significantly changes depending on the level of the other predictor.


## Curb Weight and Horsepower are statistically significant predictors of a City MPG
```{r}
reg3 = lm(citympg~curbweight+horsepower, data = car_price )
```



### Establishing our null and alternative hypothesis
As we discussed above, we plan on running an F-test to test the overall significance of both the curb weight of the car and horsepower as a predictor of city miles per gallon. 

In order to test the significance of the overall regression model, we establish the null and alternative hypothesis as such:
    - Null Hypothesis: β1 = β2 = 0. This means that none of the variables have an overall significance in the regression model
    - Alternative Hypothesis: At least one βn ≠ 0. This means that at least one predictor variable is significant in our multiple regression model.
    
    
In addition to testing the significance of the overall regression model, we will test the significance of each individual predictor variable in our model, curbweight and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the predictior variable we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the individual predictor variable is significant in the overall model.
    

### Checking our Assumptions

#### The Mean of ε is ZERO
The first assumption that we will check is that the mean of the error term, ε, is zero. This assumption means that the model is not biased.
```{r}
residuals = reg3$residuals
mean(residuals)
```
As you can see from the above code, the mean of the residuals is approximately zero, therefore we can check off this assumption.

#### Constant Variance
The second assumption that we will check is that we have constant variance.
```{r, echo = FALSE}
library(ggplot2)
ggplot(reg3, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")
```

This assumption may not hold exactly because we can see that the residuals do not have constant variance for all values.

#### Error Term is Normal
The next assumption that we check is that error term is normal. 
```{r, echo = FALSE}
# Q-Q plot
ggplot(reg3, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Q-Q Plot")

```



From the QQ plot above, with its distribution, we can conclude that the assumption that the error term of ε is normal.

#### ϵi are Independent
In order to test this assumption, we would need to have a time variable included in the model. However, there is no time variable in the regression model to test this hypothesis.

### Performing tests
Now that we have checked our assumptions, we will move forward with reporting our test statistics and p-values for our tests. It will be important to note that we will need to proceed with caution because assumption 2, constant variance, is not met within our current data set.

#### F Test for Overall Model Significance
First, we will examine the F-test statistic to determine if the multiple regression model that uses curb weight and horsepower as a predictor of city miles per gallon.
```{r}
summary(reg3)
```
As shown by the summary, the F-statistic of this test is 233.3. There is a p-value reported of <0.05, meaning that we can reject our null hypothesis. From our test, we can conclude that we can reject our null hypothesis and say that at least one of predictor of curb weight and horsepower are significant predictors of city mpg. However, it is important to proceed with caution with this because not all of our assumptions above were met.

An adjusted R2 value of 0.6949 implies that 69.49% of the variation in city miles per gallon can be explained by the regression relationship between curb weight and horsepower. In addition, a RMSE value of 3.614 shows that there is relatively low error in the model.


#### T Test for Individual Variable Significance
While it is important to show how these variables work together, it is also important to check if they are significant predictors on their own. For this, we will reference the above summary and perform one-sample t-tests.

The predictor variable of curb weight has a test statistic value of -6.096. With a p-value of less than 0.05, we can conclude that we can reject our null hypothesis and say that curb weight is a significant predictor of city mpg in our multiple regression model.

The predictor variable of horsepower has a test statistic value of -9.114, With a p-value of less than 0.05, we can conclude that we can reject our null hypothesis and say that horsepower is a significant predictor of city mpg in our multiple regression model.


# Business Value Proposition

```{r, echo=FALSE}
knitr::include_graphics("/Users/livib/OneDrive/ISA616/ISA616/Car BVP.png")
```

## 1. Client

The client for this is a Chinese car company, Geely Auto. The client is trying to enter the US Market and setting up their manufacturing unit in the U.S. They are also trying to have a competitive edge and give competition for their US and European counterparts. 


## 2. Client Jobs

The client, Geely Auto, is trying to enter the US car market and setting up a manufacturing unit in the US. The client is trying to understand the factors affecting the pricing of cars in the American car market. They are also learning to understand different cultural differences between the two markets and the consumers within it. Geely Auto also needs to understand there are different factors the impact the price of the car and American's value different aspects of cars that might differ from the Chinese market which the client is used to. 


## 3. Client Pains

One pain that Geely Auto may be experiencing is due to the fact that they are coming over from China, and may not understand the American market base. Because they are coming from a different country and culture, Geely Auto has to understand the different business models and approaches. In addition, consumers from these two countries may have different preferences as it relates to sizes and models of cars. For example, one culture may like having trucks more than others so this may impact the product portfolio offerings. In addition, the two countries may have different business and approaches to manufacturing that may impact the company's bottom line.


Through our analysis, we found that the curb weight of the car is a significant predictor of car price. With further research, we learned that different sized vehicles have price points that are grouped in relativity to a vehicle’s size. For example, large trucks often have more material that is required in order to build them as opposed to smaller sedan vehicles. So, as a result these large trucks are often more expensive in terms of price. However, they are structured differently in terms of profit margins which is important for Geely to consider has they try to decide which types of cars they should spend time producing.


Another pain that Geely Auto may find as they explore what features impact the price of the car, is that some features compromise the performance of others as they are added to the vehicle model. For example, we found that in our research, features such as the weight of the car and the horsepower may negatively impact the fuel efficiency of the vehicle. Different consumers may have different interpretations of what they value and are willing to spend on a car based on their needs and preferences. These features often interact together to impact price, so it is important to consider their effects together as opposed to separate.
 


## 4. Client Gains

From moving from China to the US, one gain that Geely can expect to see is increased market share in the automotive market space. This will allow a larger customer base to become more knowledgeable about Geely and its products, thus making their company more available and accessible to new consumers, and leading to new sales opportunities.

Another gain that Geely can expect is an increased return on their investment from moving to the US. While it will be costly to set up a manufacturing plant in the US, the company will ultimately become available to a wider consumer base, thus leading to increased sales and profits for the company, which makes it an enticing opportunity.

An additional gain that Geely can expect from our solution is the creation of a brand identity that relates to an American audience. Coming from China, Geely Auto currently does not understand the American market enough to be a competitor within an already established market space. With our knowledge and insights, we will be able to provide Geely with more information, allowing them to create a brand identity that allows them to appeal to American consumers and capture their business.



## 5. Intended Solution

For the intended solution Geely Auto should be more aware of how the cars should be priced in the American market. We want to make Geely Auto aware of what is considered too expensive or too cheap so they can sell cars and enter into the market, but still have a competitive advantage. We want to give insights on the American market, more specifically on what features can impact car price. We will give a better understanding of what types of cars are preferred in the American market. For example, many American consumers prefer bigger cars such as trucks or cars with more horsepower. Both preferences require more materials which can increase the price of cars. The more cars made are geared towards the American consumer preferences that can equate to higher price points and profits. 

Another solution for Geely Auto is building brand awareness and investing in marketing campaigns to ensure trust among consumers. Also by establishing partnerships with local dealers can create a reliable network for sales and customers. Geely Auto also needs to be able to adapt to local needs such as vehicle features and services to meet specific needs and perferences of different American consumers since there is such a difference in landscapes and terrain across the entire US. 


## 6. Pain Killers

Through our solution, we will be able to ease Geely Auto’s transition to America by providing them with the knowledge and resources they need to understand the American market and consumers. Through this, they will also be able to better understand what specific features of a car impact the price of a vehicle, specifically in the US.

In addition, our solution will also relieve the pain of trying to understand how different parts of a vehicle interact with one another. Through our analyses, we tested the interactions between variables and how some affected others. Geely Auto will be able to take this information and translate it into their business model when deciding which features of a car to prioritize for the American market.


## 7. Gain Creators

From our solution, Geely will be able to create models of cars that directly appeal to the American consumer and market. This is because our analysis will allow them to have a more holistic picture of which features impact car price the most in America. Having this understanding will ultimately help ease the transition from the Chinese to American market for Geely and set them up for success in a new place. 

In addition, our insights and solution will allow Geely Auto to capture more market share and audience base through their expansion efforts to America. This is because they will have the tools they need to better understand pricing within the American market, allowing them to stay competitive with their American and European competitors. In turn, we hope that this will also contribute to additional revenue and profits for Geely Auto through this wider consumer base, which will ultimately have a high payoff for the company’s bottom line.




