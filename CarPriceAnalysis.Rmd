---
title: "Car Price Analysis"
author: "Analysis by: Alyssa Aey, Olivia Bickford, and Lauren Pagel"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
date: "2024-09-09"
---


In this analysis, we will be exploring one set of data that is focused on different car features that may impact the sale price of a car. The set of data is taken from different car observations.

The data set we will be examining consists of 12 variables, 11 of which are classified as predictor variables. 11 of these variables are observatory, while 1, symboling, represents an assigned insurance risk rating for the vehicle.

This data set will be read into R from a CSV file and will be named as car_price during our analysis.

# Descriptive Summary

## Data Structure
```{r, echo = FALSE}
## load the dataset
car_price <- read.csv('CarPrice.csv')
```

Once the data set is loaded into the software, we first want to examine the structure of the data set. This will give us an idea of what variables are present, as well as what types they are as we begin to perform our analysis.

```{r, echo=FALSE}
str(car_price)
```
From this, we can see that all of our predictor variables are either numeric or an integer, besides the drivewheel, which is classified as a character. From this one line of code we are also able to see that we have a total of 205 observations across 11 predictor variables and one response variable.
```{r, echo=FALSE}
head(car_price)
```
Shows the first few observations of the data set.
```{r, echo=FALSE}
tail(car_price)
```
Shows the last few observations of the car_price data set.

## Summary Statistics
```{r, echo=FALSE}
## Show summary of all variables in dataset
summary(car_price)
```


This showcases summary statistics for each variable in the model. These summary statistics will be referenced later on when looking for outliers in the data set and provide useful information about the distribution of values.


## Data Quality Assessment
Before doing any initial analysis on the data, it is important to understand the overall quality of the current data that we are given. Without quality data, we are unable to draw any meaningful conclusions, so it is important that all data quality problems are taken care of immediately.

First, we will check for any missing values in our dataset.
```{r, echo=FALSE}
## Check for Missing Values
missing_values <- car_price |> 
  dplyr::summarise_all(~ sum(is.na(.)))

print(missing_values)
```
There are no missing values in the car prices data set.

Next, we will look to see if any of the rows have duplicated values.
```{r,echo=FALSE}
## Check for duplicated rows
duplicate_rows <- car_price |> 
  dplyr::filter(duplicated(car_price))

print(duplicate_rows) 
```
We found that there were two rows duplicated in our data set. However, by looking closer at the values, only 6 out of 11 possible predictor variables were exact duplicates of one another. Because this does not appear to be an exact duplicate of records, we will continue with our analysis.

The next step in ensuring data quality is to examine the distribution of predictor variables to see if there are any outliers.
```{r, echo=FALSE}
numeric_data <- car_price[sapply(car_price, is.numeric)]
boxplot(numeric_data, main = "Boxplot of Car Prices Data Set", ylab = "Values", las = 2)
```

From creating a boxplot of all predictor variables in the data set, we can see that variables wheelbase, carlength, cylinder number, stroke, horsepower, peakrpm, and citympg have at least one outlier. In addition, our response varaible, price, has at least one outlier present. Let's investigate further.
```{r, echo=FALSE}
boxplot(car_price$wheelbase, main = "Distribution of Wheelbase",
        ylab = "Values")
```
It looks like there are two outliers of the wheelbase variable.
```{r, echo=FALSE}
summary(car_price$wheelbase)
```

According to [carparts.com](https://www.carparts.com/blog/what-is-the-wheelbase-and-how-does-it-affect-car-performance/#:~:text=For%20example%2C%20a%20city%20car,typically%20has%20around%20117%20inches) the wheelbase size is typically dependent on the size of the car. For instance, a city car typically has a 95 inch wheelbase while a large SUV has around 117 inches. With a max value of 120.90 inches, our outliers for this variable do not appear to be very far removed from the dataset at all, and are likely a better indication of a larger vehicle. Thus, we will leave these observations in our data set. 

The next variable we will investigate is the length of the car.
```{r, echo=FALSE}
boxplot(car_price$carlength, main = "Distribution of Car Length",
        ylab = "Values")
```

Looking at the distribution of values of the car length variable, it appears we have one outlier. Let's take a look at the summary statistics.
```{r, echo=FALSE}
summary(car_price$carlength)
```

According to [carfromjapan.com](https://carfromjapan.com/article/car-maintenance/what-is-the-average-car-length-and-how-to-find-it/), the length of a small car can be anywhere between 118 and 169.3 inches. With this information, we can see that our small outlier clearly falls within the range. We are free to proceed with this data point in our data set.

The next variable we will look at is the cylinder number of the car.
```{r, echo=FALSE}
boxplot(car_price$cylinder.number, main = "Distribution of cylinder number",
        ylab = "Values")
```

According to [Kia](https://www.kia.com/dm/discover-kia/ask/what-is-a-cylinder-in-a-car.html#:~:text=The%20cylinder%20consists%20of%20a,6%2C%20or%208%20cylinder%20engine.), most cars have either a 4, 6, or 8, cylinder engine, however it is possible to have more or less than that. With this information, we can determine that we are safe to proceed with these observations in our data.

The next variable with outliers present is the stroke of the engine.
```{r, echo=FALSE}
boxplot(car_price$stroke, main = "Distribution of Stroke",
        ylab = "Values")
```

The values for the distribution of the stroke do not seem like outliers. With some additional research, most cars have a 3-stroke engine. However, a lot of modern cars have a 4-stroke engine and many older cars have a 2-stroke engine.This information was found from [Prime Source](https://primesourceco.com/latest-news/the-difference-between-a-2-stroke-and-4-stroke-engine/#:~:text=While%204%2Dstroke%20engines%20perform,stroke%20is%20more%20fuel%2Defficient). Thus, we can conclude that these values are likely not outliers and are more indicative of the age of the car.

The next variable that we will examine for outliers is the horsepower of the engine.
```{r, echo=FALSE}
boxplot(car_price$horsepower, main = "Distribution of Horsepower",
        ylab = "Values")
```

By closely looking the boxplot for the horsepower of an engine, our outliers for this variable appeared to be skewed towards high values in the dataset. According to [AutoList](https://www.autolist.com/guides/average-car-horsepower), the horsepower for car engines most often depends on the size of the car. For small cars, a good horsepower is typically between 100-150. For midsize cars, a good horsepower is around 200. For large cars, a good horsepower is around 300. In addition, a good horsepower for a sports car falls above 300. Thus, these higher values are likely not outliers in the dataset and are likely better indicators of the type of car.

The next variable we will examine for outliers is PeakRPM.
```{r, echo=FALSE}
boxplot(car_price$peakrpm, main = "Distribution of Peak RPM",
        ylab = "Values")
```

From this boxplot, it appears that we have one outlier of peak RPM in our dataset. According to [Auto Hero](https://www.autohero.com.au/blog/what-does-rpm-mean-in-a-car/#:~:text=What%20is%20maximum%20RPM%20for,lower%20%E2%80%93%20usually%20around%204%2C000RPM.), the peak RPM of a car depends on the type of engine used. For example, petrol engines have a max RPM between 5,000 and 7,000RPM. Diesel engines have a lower max RPM around 4,000RPM, however most cars under normal driving conditions operate between 1,500-3,000RPM. The summary statistics shown earlier indicates a maximum value in our data set of 6600, which we can conclude is an acceptable value to leave in our data set.

The final predictor variable we will check for outliers is the city miles per gallon.
```{r, echo=FALSE}
boxplot(car_price$citympg, main = "Distribution of City MPG",
        ylab = "Values")
summary(car_price$citympg)
```

The two outliers in our boxplot do not appear to be very far away from the range in our boxplot. In addition, according to research from [Car and Driver](https://www.caranddriver.com/research/a31518112/what-is-good-gas-milage/), these outliers are possible potential values for gas mileage and thus should be left in the data.

As mentioned previously, our response variable, price, also had a few outliers visible. Let's take a closer look at this:
```{r, echo=FALSE}
boxplot(car_price$price, main = "Distribution of Price",
        ylab = "Values")
```
From this boxplot, it appears that our data is slightly skewed to the right with higher car prices in the data set. According to the summary statistics above, the maximum price of a car in our data is $45,400. [Yahoo Finance](https://finance.yahoo.com/news/car-prices-drop-2024-auto-120055933.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAE6-YTs4XuYqnckDJIgBBxcNMXUL9__xXwcnBgqjTZB2fmEts9HnM1pKg00IkW_hSkr2t5shJpiujBZ17VyIIDQwEByhD9gWDIEiIQRh9ZGcUuiV85qGZ-rh_Z0Pc54-UAzRCvrR_KYzm7MPOleOkRxB_wLmf5397P3len-sY1ti) states in their article that the average new car in October of 2023 was selling for $47,936. From this new information, we can take note that as new cars are added to our data set, the car prices will start to shift towards our current outlier values, meaning that it is okay to proceed with these values in our data set.

Now that we have closely checked for data quality in our data set, we will proceed by examining correlations between variables and begin to understand the relationships they may have on car price.

## Visualizations
This section will primarily focus on building visualizations to better understand the data and correlations between variables.

To start, we will compute the correlations for each numeric predictor variable with the response
```{r, echo=FALSE}
# Identify numeric columns
numeric_vars <- sapply(car_price, is.numeric)

# Extract only numeric columns
car_price_numeric <- car_price[, numeric_vars]

# Extract the dependent variable 'price'
dependent_var <- car_price_numeric$price

# Compute correlations with the dependent variable
correlations <- sapply(car_price_numeric, function(x) {
  if (identical(x, dependent_var)) {
    NA  # Skip the correlation of 'price' with itself
  } else {
    cor(x, dependent_var, use = "complete.obs")
  }
})

# Print correlations
print(correlations)
```

From this block of code, we are able to view the correlations each of our numeric predictor variables with the response variable, car price. The correlation coefficient, r, indicates the strength and direction of each correlation, with the strongest correlation values approaching either -1 or +1 based on the direction.

From this information, we notice that the predictor variable with the strongest regression relationship with car price is the curbweight of the car. Let's investigate this further.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = curbweight, y = price) +
  geom_point() +
  scale_color_hue()
```

As indicated by the correlation coefficient of 0.8353, we see from a scatterplot of the data points that as the weight of the car increases, the overall price of the car also tends to increase. These variables appear to have a relatively strong relationship with one another. There may even be a statistically significant linear relationship between these variables, however further testing and modeling would be needed.

From the correlation coefficients shown above, horsepower was also showen to be a relatively strong predictor of car price. Let's examine its scatterplot.

```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = horsepower, y = price) +
  geom_point() +
  scale_color_hue()
```
Similar to the curbweight of the car, we find that typically as the horsepower of the car increases, so does its price. These variables also have a relatively strong relationship with one another (r = 0.8081), indicating that there may even be a statistically significant relationship between these predictors, however, more analysis would be needed to prove this.

Let's look at a variable with a relatively low correlation coefficient, stroke.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = stroke, y = price) +
  geom_point() +
  scale_color_hue()

```

As indicated by its correlation coefficient (r = 0.0794), there is a weak relationship present between stroke and the price of a car. Further analysis would be needed, but this may be an indication of a statistically insignificant relationship between the variables, meaning that an engine's stroke may not be a good indicator of a car's price.

With some of this information, let's generate a correlation matrix.
```{r, echo=FALSE}
# Install the corrplot package if it's not already installed
if (require(corrplot) == FALSE) install.packages("corrplot")

# Load the corrplot package
corrplot::corrplot(cor(car_price_numeric))

car.cor = cor(car_price_numeric)
corrplot(car.cor)
```

Above is a correlation matrix of all of our numeric predictor variables. This plot shows the relationship that all of our predictor variables have with the response as well as the relationships the predictor variables have with one another. This is particularly useful to best understand the relationships present in the dataset for further analysis in the future.

While we were able to examine all of the correlation coefficients for our numeric predictors, we were unable to see if our one categorical predictor, drivewheel has any impact on the car price.
```{r, echo=FALSE}
library(ggplot2)
ggplot(car_price) +
  aes(x = drivewheel, y = price) +
  geom_point() +
  scale_color_hue()
```

This plot categorizes the observations by the type of drive wheel it has, either "rear-wheel drive" or "other." From the plot generated, we see that vehicles classified as having a rear-wheel drive typically have a higher car price than those categorized as other. This indicates that there could potentially be a relationship between the drivewheel of a vehicle and car price, however we would still need further analysis.

# Observation, Research, Hypothesis
In this section of our analysis, we will focus on developing hypotheses that may be relevant to better understanding the relationships between our predictor variables and car price. 

## Curb Weight is a Statistically Significant Predictor of Car Price
In the above section, we examined the correlations between each predictor variable and car price. With a correlation coefficient of 0.8353, we see that there is a relatively strong positive correlation between the curb weight of a car and the car price. As the curb weight of the car increases, the car price tends to increase as well.

### Doing Research
The vehicle's curb weight is defined as the weight of the vehicle. This includes a full tank of fuel and all standard equipment such as motor oil, transmission oil, and brake fluid. This differentiates from a vehicle's gross weight which denotes the total weight from a vehicle when it is fully loaded with passengers, cargo, and additional equipment. 

It is also said that curb weight "acts as a baseline measurement that directly impacts several aspects of vehicle performance." These aspects include fuel efficiency and acceleration. It is said that vehicles with lower curb weights reduce the amount of power required to move the vehicle, which result in less fuel consumed. In addition, lighter vehicles have an advantage when it comes to acceleration. However, when we look at vehicle stability in adverse weather conditions, heavier vehicles hold their ground better. 

For the most part, larger cars have larger gas tanks than smaller cars. Small cars usually hold up to 12 gallons gas, some larger cars can carry 15 gallons of gas, and many larger trucks can hold anywhere from 21-38 gallons of gas. 

Through research, there is no definitive answer as to how the size of a car's gas tank and the price of the car are related. However, we can say that as the size of gas tanks increase, so does the overall curbweight of the car. Perhaps the extra sales price that is shown from the positive correlation is a better result of the additional materials cost to build a larger car.

### Testing this Hypothesis
In order to test this hypothesis, we want to run a regression model to show its validity. Our regression model will use curbweight as the predictor variable and car price as the repsonse variable. From there we will run a one-sample t-test to examine whether there is a significant regression relationship between curbweight and car price.

## Horsepower and Amount of Cylinders is a Statistically Significant Predictor of Car Price

Above horsepower and price have a positive correlation of 0.808 so we see there is a strong, positive linear correlation between these two variables. So, as the horsepower of a car increases the price tends to increase. Between amount of cylinders and price, there is also a strong positive correlation of 0.718. This means that as the price increases as the amount of cylinders increases. On the correlation plot, horsepower and the amount of cylinders has a strong positive linear association. 


### Doing Research

Horsepower is the power of the engines and the rate at which work is done. Horsepower sustains the momentum and higher rate of work once the car is moving. The higher the horse power, the faster the engine will accelerate at speed. Horsepower shows the performance of a car, an engine with more horsepower will accelerate more quickly and can lead to more towing reliability. With this however, higher horsepower can often lead to lower gas mileage and efficiency. 

The cylinder is the power unit of the engine and there are usually 4, 6 or 8 in a car. These take fuel and burn it so it is turned into energy that in turn powers the vehicle. It has the base of a piston that moves the cylinder up and down to form the reaction and combustion. The more cylinders means more pistons leading to more fuel being turned into power. 

With research there seems to be no definitive answers about horsepower and cylinder are related to a higher car price. However, it seems that the more horsepower the car is stronger and the more cylinders there are the more gas and power the car is producing. The additional price increase could be due to more advanced and powerful technology required for having a higher horsepower. The higher the performance could require more expensive components in order for the car to preform up to standard. The more cylinders usually means larger engines in order to fit everything properly so there could be an increased in the complexity of materials needed to fit multiple cylinders. 

Thinking about fuel efficiency, cars with larger engines have a lower fuel efficiency and higher emissions due to the amount of gas required to power the car. With many business and governments putting rules in place about environmental regulations, the manufacturer might have to add an increase in price to comply with the rules due to cars with more horsepower and more cylinders that could contribute more to carbon emissions. 


### Testing this Hypothesis

In order to test this hypothesis a multiple regression could be used to model the relationship since there are strong positive correlation values between the variables and adding in interaction terms to see if horsepower depends on the number of cylinders or vise versa. 

Our model would use horsepower and number of cylinders as predictor variables and car price as the response. We would use a one sample t-test to compare the average prices and see if there is a significant relationship between the two variables and the predictor. From there we would assess the model fit with R-squared values, residual analysis and test sets. 

## Curb Weight and Horsepower are statistically significant predictors of a City MPG
We generated this hypothesis from the results of our correlation matrix. From this we noticed that there were relatively large negative correlations between these variables. 
```{r}
cor(car_price$curbweight, car_price$citympg, use = "complete.obs")
```
This line of code shows that curb weight has a relatively strong negative relationship with city mpg. This means that as curb weight tends to increase, the miles per gallon the car gets tends to decrease.
```{r}
cor(car_price$horsepower, car_price$citympg, use = "complete.obs")
```
This line of code confirms what we have seen from our correlation matrix and even suggests that horsepower is a stronger predictor of city mpg than the curb weight of the car is. We will continue to work with our hypothesis that both are strong predictors of city mpg, but horsepower may even be one on its own.

### Doing Research
One critical factor that we saw from doing research on both horsepower and the curb weight of the car is something called a [Power to Weight Ratio](https://www.jtech.org/power-to-weight-ratio-and-how-it-affects-performance/). Essentially, the power to weight ratio is calculated by dividing the horsepower of the car by the weight of the car. According to the article, the ideal performance of a car is lighter in curb weight but high in the amount of horsepower.

Of course, it depends how you would want to describe vehicle performance, which could mean different things depending on the context of the situation. In this scenario, we will be looking at vehicle performance in the context of miles per gallon the vehicle is able to get.

Regression analyses has been done to show the regression relationship between both horsepower, curb weight, and city mpg. In a study done by [Fort Hays State University](https://scholars.fhsu.edu/cgi/viewcontent.cgi?article=1427&context=sacad), both the weight and horsepower of a car are shown to be statistically significant predictors of the fuel efficiency (mpg) of a vehicle. 

Other [studies](https://finelineimports.net/2019/10/does-more-horsepower-mean-fewer-mpg/) have shown the exact opposite, that horsepower is not an issue that can affect fuel economy. This approach claims that there are a variety of other factors that impact a vehicle's fuel efficiency such as "easing off of the accelerator, cutting down on some of the weight inside your vehicle, keeping tires inflated to the proper pressure, reducing drag as much as possible, and taking routes you won't have to stop as frequently." 

Because of the mixed results we found through our outside research, particularly in regards to horsepower, it makes it all the more important to test our hypothesis on our own data set before jumping to any conclusions.

### Testing this Hypothesis

In order to test this hypothesis, we will build a multiple regression model using both horsepower and curbweight as predictor variables and city miles per gallon as the response variable. 

After building the regression model, we will examine the F test statistic in order to determine the overall model significance. In addition, measures such as the adjusted R2 and RMSE will provide insight into how well our model performs. In addition, one-sample t-tests can be performed on each predictor variable in order to test their individual significance to the model.

# Running our Analyses
Now that we have identified, three potential hypotheses to test we need to test them to see if they hold true in our model

## Curb Weight is a Statistically Significant Predictor of Car Price

reg1=lm(price~curbweight, data = car_price)
options(scipen = 999)
summary(reg1)
anova(reg1)

## Horsepower and Amount of Cylinders is a Statistically Significant Predictor of Car Price

```{r, echo = FALSE}
Model1 <- lm(price ~ horsepower + cylinder.number + horsepower:cylinder.number, data = car_price)
```


### Establishing Null and Alternative Hypothesis

As we discussed above, we plan on running an F-test to test the overall significance of both the horsepower of the car, the amount of cylinders and the interaction between them as a predictor of car price.


In order to test the significance of the overall regression model, we establish the null and alternative hypothesis as such:
    - Null Hypothesis: β1 = β2 = 0. This means that none of the variables have an overall significance in the regression model
    - Alternative Hypothesis: At least one βn ≠ 0. This means that at least one predictor variable is significant in our multiple regression model.

In addition to testing the significance of the overall regression model, we will test the significance of each individual predictor variable in our model, number of cylinders and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the predictior variable we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the individual predictor variable is significant in the overall model.
  
In addition to testing the significance of the overall regression model, we will test the significance of the interaction terms between the number of cylinders and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the interaction term we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the interaction term is significant in the overall model.
  
### Checking our Assumptions

#### The Mean of ε is ZERO

The first assumption that we will check is that the mean of the error term, ε, is zero. This assumption means that the model is not biased.
```{r}
residuals = Model1$residuals
mean(residuals)
```

As you can see from the above code, the mean of the residuals is approximately zero, therefore we can check off this assumption.


#### Constant Variance
The second assumption that we will check is that we have constant variance.

```{r}
plot(Model1, 1)
```


This assumption may not hold exactly because we can see that the residuals do not have constant variance for all values and the residual line is slightly skewed up.

#### Error Term is Normal

The next assumption that we check is that error term is normal.

```{r}
plot(Model1, 2)
```

From the QQ plot above, with its distribution, we can conclude that the assumption that the error term of ε is mostly normal with some of the data points being slightly under or below the line.


#### ϵi are Independent
In order to test this assumption, we would need to have a time variable included in the model. However, there is no time variable in the regression model to test this hypothesis.


### Performing tests
Now that we have checked our assumptions, we will move forward with reporting our test statistics and p-values for our tests. It will be important to note that we will need to proceed with caution because assumption 2, constant variance, is not met within our current data set.


#### F Test for Overall Model Significance

First, we will examine the F-test statistic to determine if the multiple regression model that uses horsepower, number of cylinders and the interaction between them as a predictor of price.

```{r}
summary(Model1)
```

```{r}
anova(Model1)
```



As shown by the summary, the F-statistic of this test is 171.1. There is a p-value reported of <0.001, meaning that we can reject our null hypothesis. From our test, we can conclude that we can reject our null hypothesis and say that at least one of predictor of horsepower, number of cylinders and the interaction term are significant predictors of car price. However, it is important to proceed with caution with this because not all of our assumptions above were met.

An adjusted R2 value of 0.7144 implies that 71.44% of the variation in car price can be explained by the regression relationship between horsepower and number of cylinders. In addition, a RMSE value of 4269 shows that there is a higher average size of the residuals. This means we should proceed with caution.


#### T Test for Individual Variable Significance

While it is important to show how these variables work together, it is also important to check if they are significant predictors on their own. For this, we will reference the above summary and perform one-sample t-tests.

The predictor variable of number of cylinders has a test statistic value of 5.602 With a p-value of less than 0.001, we can conclude that we can reject our null hypothesis and say that number of cylinders is a significant predictor of car price in our multiple regression model.

The predictor variable of horsepower has a test statistic value of 8.221, With a p-value of less than 0.001, we can conclude that we can reject our null hypothesis and say that horsepower is a significant predictor of car price in our multiple regression model.

### Interaction Terms

The interaction between horsepower and cylinder number shows how the effect of horsepower on the car price changes depending on the level of the other predictor, cylinder number. Since the p-value for the interaction terms is <0.001, the effect of one predictor on car price significantly changes depending on the level of the other predictor.



## Curb Weight and Horsepower are statistically significant predictors of a City MPG


```{r, include = FALSE}
reg3 = lm(citympg~curbweight+horsepower, data = car_price )
options(scipen = 999)
summary(reg3)
anova(reg3) ## SSE
```


### Establishing our null and alternative hypothesis
As we discussed above, we plan on running an F-test to test the overall significance of both the curb weight of the car and horsepower as a predictor of city miles per gallon. 

In order to test the significance of the overall regression model, we establish the null and alternative hypothesis as such:
    - Null Hypothesis: β1 = β2 = 0. This means that none of the variables have an overall significance in the regression model
    - Alternative Hypothesis: At least one βn ≠ 0. This means that at least one predictor variable is significant in our multiple regression model.
    
    
In addition to testing the significance of the overall regression model, we will test the significance of each individual predictor variable in our model, curbweight and horsepower. We will use a t-test to compute these test statistics with the null and alternative hypothesis as such:
  - Null Hypothesis: βn = 0. This means that the predictior variable we are examining is not significant in our model.
  - Alternative Hypothesis: βn ≠ 0. This means that the individual predictor variable is significant in the overall model.
    

### Checking our Assumptions

#### The Mean of ε is ZERO
The first assumption that we will check is that the mean of the error term, ε, is zero. This assumption means that the model is not biased.
```{r}
residuals = reg3$residuals
mean(residuals)
```
As you can see from the above code, the mean of the residuals is approximately zero, therefore we can check off this assumption.

#### Constant Variance
The second assumption that we will check is that we have constant variance.
```{r, echo = FALSE}
library(ggplot2)
ggplot(reg3, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")
```

This assumption may not hold exactly because we can see that the residuals do not have constant variance for all values.

#### Error Term is Normal
The next assumption that we check is that error term is normal. 
```{r, echo = FALSE}
# Q-Q plot
ggplot(reg3, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Q-Q Plot")

```

From the QQ plot above, with its distribution, we can conclude that the assumption that the error term of ε is normal.

#### ϵi are Independent
In order to test this assumption, we would need to have a time variable included in the model. However, there is no time variable in the regression model to test this hypothesis.

### Performing tests
Now that we have checked our assumptions, we will move forward with reporting our test statistics and p-values for our tests. It will be important to note that we will need to proceed with caution because assumption 2, constant variance, is not met within our current data set.

#### F Test for Overall Model Significance
First, we will examine the F-test statistic to determine if the multiple regression model that uses curb weight and horsepower as a predictor of city miles per gallon.
```{r}
summary(reg3)
```
As shown by the summary, the F-statistic of this test is 233.3. There is a p-value reported of <0.05, meaning that we can reject our null hypothesis. From our test, we can conclude that we can reject our null hypothesis and say that at least one of predictor of curb weight and horsepower are significant predictors of city mpg. However, it is important to proceed with caution with this because not all of our assumptions above were met.

An adjusted R2 value of 0.6949 implies that 69.49% of the variation in city miles per gallon can be explained by the regression relationship between curb weight and horsepower. In addition, a RMSE value of 3.614 shows that there is relatively low error in the model.


#### T Test for Individual Variable Significance
While it is important to show how these variables work together, it is also important to check if they are significant predictors on their own. For this, we will reference the above summary and perform one-sample t-tests.

The predictor variable of curb weight has a test statistic value of -6.096. With a p-value of less than 0.05, we can conclude that we can reject our null hypothesis and say that curb weight is a significant predictor of city mpg in our multiple regression model.

The predictor variable of horsepower has a test statistic value of -9.114, With a p-value of less than 0.05, we can conclude that we can reject our null hypothesis and say that horsepower is a significant predictor of city mpg in our multiple regression model.




